{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threading parameters before importing TensorFlow\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Concatenate, Multiply, Permute, Lambda, Reshape, Activation, Dropout, Add, GlobalMaxPooling1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "csv_directory = \"D:\\MTdataset\\DL_dataset\\Python_DL\\Final_current_vibration_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current and vibration data\n",
    "current_files = [file for file in os.listdir(csv_directory) if 'current' in file]\n",
    "vibration_files = [file for file in os.listdir(csv_directory) if 'vibration' in file]\n",
    "\n",
    "current_dfs = [pd.read_csv(os.path.join(csv_directory, file)) for file in current_files]\n",
    "vibration_dfs = [pd.read_csv(os.path.join(csv_directory, file)) for file in vibration_files]\n",
    "\n",
    "# Combine all current data and vibration data into single DataFrames\n",
    "current_data = pd.concat(current_dfs, ignore_index=True)\n",
    "vibration_data = pd.concat(vibration_dfs, ignore_index=True)\n",
    "\n",
    "# Ensure your data is in the float32 format\n",
    "def convert_to_float32(data):\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "current_data = convert_to_float32(current_data)\n",
    "vibration_data = convert_to_float32(vibration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no missing values\n",
    "current_data = current_data.dropna()\n",
    "vibration_data = vibration_data.dropna()\n",
    "\n",
    "# Ensure data is numeric\n",
    "current_data = current_data.apply(pd.to_numeric)\n",
    "vibration_data = vibration_data.apply(pd.to_numeric)\n",
    "\n",
    "# Print shapes and first few rows of raw data for debugging\n",
    "print(\"Raw current_data shape:\", current_data.shape)\n",
    "print(\"Raw vibration_data shape:\", vibration_data.shape)\n",
    "print(\"Raw current_data head:\\n\", current_data.head())\n",
    "print(\"Raw vibration_data head:\\n\", vibration_data.head())\n",
    "\n",
    "# Visualize data using box plots\n",
    "def visualize_data(data, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=data)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize data before outlier removal\n",
    "visualize_data(current_data.iloc[:, 1:], \"Current Data Before Outlier Removal\")\n",
    "visualize_data(vibration_data.iloc[:, 1:], \"Vibration Data Before Outlier Removal\")\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "def remove_outliers_iqr(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data_no_outliers = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return data_no_outliers\n",
    "\n",
    "# Remove outliers\n",
    "current_data_no_outliers = remove_outliers_iqr(current_data.iloc[:, 1:])\n",
    "vibration_data_no_outliers = remove_outliers_iqr(vibration_data.iloc[:, 1:])\n",
    "\n",
    "# Print shapes and first few rows of no outliers data for debugging\n",
    "print(\"no outliers current_data shape:\", current_data_no_outliers.shape)\n",
    "print(\"no outliers vibration_data shape:\", vibration_data_no_outliers.shape)\n",
    "print(\"no outliers current_data head:\\n\", current_data_no_outliers.head())\n",
    "print(\"no outliers vibration_data head:\\n\", vibration_data_no_outliers.head())\n",
    "\n",
    "# Determine the maximum length for padding\n",
    "max_length = max(len(current_data_no_outliers), len(vibration_data_no_outliers))\n",
    "\n",
    "# Padding function\n",
    "def pad_data(data, target_length):\n",
    "    current_length = len(data)\n",
    "    if current_length < target_length:\n",
    "        padding_length = target_length - current_length\n",
    "        padding = np.zeros((padding_length, data.shape[1]))\n",
    "        data_padded = np.vstack((data, padding))\n",
    "        return data_padded\n",
    "    return data\n",
    "\n",
    "# Pad the datasets to the same length\n",
    "current_data_no_outliers_padded = pad_data(current_data_no_outliers.values, max_length)\n",
    "vibration_data_no_outliers_padded = pad_data(vibration_data_no_outliers.values, max_length)\n",
    "\n",
    "# Re-add the 'Time' column after removing outliers\n",
    "current_data_no_outliers_padded = pd.DataFrame(current_data_no_outliers_padded, columns=current_data.columns[1:])\n",
    "current_data_no_outliers_padded.insert(0, 'Time', current_data['Time'][:max_length].values)\n",
    "\n",
    "vibration_data_no_outliers_padded = pd.DataFrame(vibration_data_no_outliers_padded, columns=vibration_data.columns[1:])\n",
    "vibration_data_no_outliers_padded.insert(0, 'Time', vibration_data['Time'][:max_length].values)\n",
    "\n",
    "# Visualize data after outlier removal\n",
    "visualize_data(current_data_no_outliers_padded.iloc[:, 1:], \"Current Data After Outlier Removal and Padding\")\n",
    "visualize_data(vibration_data_no_outliers_padded.iloc[:, 1:], \"Vibration Data After Outlier Removal and Padding\")\n",
    "\n",
    "# Print shapes and first few rows of no outliers data for debugging\n",
    "print(\"after Padding current_data shape:\", current_data_no_outliers_padded.shape)\n",
    "print(\"after Padding vibration_data shape:\", vibration_data_no_outliers_padded.shape)\n",
    "print(\"after Padding current_data head:\\n\", current_data_no_outliers_padded.head())\n",
    "print(\"after Padding vibration_data head:\\n\", vibration_data_no_outliers_padded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes and first few rows of no outliers data for debugging\n",
    "print(\"after Padding current_data shape:\", current_data_no_outliers_padded.shape)\n",
    "print(\"after Padding vibration_data shape:\", vibration_data_no_outliers_padded.shape)\n",
    "print(\"after Padding current_data head:\\n\", current_data_no_outliers_padded.head())\n",
    "print(\"after Padding vibration_data head:\\n\", vibration_data_no_outliers_padded.head())\n",
    "\n",
    "# Normalize the Data\n",
    "current_scaler = StandardScaler().fit(current_data_no_outliers_padded.iloc[:, 1:])\n",
    "vibration_scaler = StandardScaler().fit(vibration_data_no_outliers_padded.iloc[:, 1:])\n",
    "\n",
    "current_data_normalized_values = current_scaler.transform(current_data_no_outliers_padded.iloc[:, 1:])\n",
    "vibration_data_normalized_values = vibration_scaler.transform(vibration_data_no_outliers_padded.iloc[:, 1:])\n",
    "\n",
    "# Add the 'Time' column back to the normalized data\n",
    "current_data_normalized = pd.DataFrame(current_data_normalized_values, columns=current_data_no_outliers_padded.columns[1:])\n",
    "current_data_normalized.insert(0, 'Time', current_data_no_outliers_padded['Time'])\n",
    "\n",
    "vibration_data_normalized = pd.DataFrame(vibration_data_normalized_values, columns=vibration_data_no_outliers_padded.columns[1:])\n",
    "vibration_data_normalized.insert(0, 'Time', vibration_data_no_outliers_padded['Time'])\n",
    "\n",
    "# Print shapes and first few rows of normalized data for debugging\n",
    "print(\"Normalized current_data shape:\", current_data_normalized.shape)\n",
    "print(\"Normalized vibration_data shape:\", vibration_data_normalized.shape)\n",
    "print(\"Normalized current_data head:\\n\", current_data_normalized.head())\n",
    "print(\"Normalized vibration_data head:\\n\", vibration_data_normalized.head())\n",
    "\n",
    "# Check the range of normalized values\n",
    "print(\"Range of normalized current_data values:\", current_data_normalized.iloc[:, 1:].min().min(), \"to\", current_data_normalized.iloc[:, 1:].max().max())\n",
    "print(\"Range of normalized vibration_data values:\", vibration_data_normalized.iloc[:, 1:].min().min(), \"to\", vibration_data_normalized.iloc[:, 1:].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences without shuffling\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data.iloc[i:i + sequence_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "# Create sequences for current and vibration data (excluding the 'Time' column)\n",
    "current_sequences = create_sequences(current_data_normalized.iloc[:, 1:], sequence_length)\n",
    "vibration_sequences = create_sequences(vibration_data_normalized.iloc[:, 1:], sequence_length)\n",
    "\n",
    "# Assume the RUL is the last value in the Time column for each sequence\n",
    "rul = current_data_normalized['Time'][sequence_length:].values\n",
    "\n",
    "# Split the sequences into training and validation sets while maintaining the order\n",
    "split_index = int(len(current_sequences) * 0.8)\n",
    "train_current_seq = current_sequences[:split_index]\n",
    "val_current_seq = current_sequences[split_index:]\n",
    "train_vibration_seq = vibration_sequences[:split_index]\n",
    "val_vibration_seq = vibration_sequences[split_index:]\n",
    "train_rul = rul[:split_index]\n",
    "val_rul = rul[split_index:split_index + len(val_current_seq)]\n",
    "\n",
    "# Print the shapes and types of sequences for debugging\n",
    "print(\"train_current_seq shape:\", train_current_seq.shape, \"dtype:\", train_current_seq.dtype)\n",
    "print(\"train_vibration_seq shape:\", train_vibration_seq.shape, \"dtype:\", train_vibration_seq.dtype)\n",
    "print(\"train_rul shape:\", train_rul.shape, \"dtype:\", train_rul.dtype)\n",
    "print(\"val_current_seq shape:\", val_current_seq.shape, \"dtype:\", val_current_seq.dtype)\n",
    "print(\"val_vibration_seq shape:\", val_vibration_seq.shape, \"dtype:\", val_vibration_seq.dtype)\n",
    "print(\"val_rul shape:\", val_rul.shape, \"dtype:\", val_rul.dtype)\n",
    "\n",
    "# Print the first few rows of the sequences\n",
    "print(\"First few rows of train_rul:\\n\", train_rul[:2])\n",
    "print(\"First few rows of val_rul:\\n\", val_rul[:2])\n",
    "\n",
    "# Create a data generator\n",
    "def data_generator(current_seq, vibration_seq, rul):\n",
    "    for i in range(len(current_seq)):\n",
    "        yield (current_seq[i], vibration_seq[i]), rul[i]\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Use tf.data.Dataset.from_generator to create datasets\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(train_current_seq, train_vibration_seq, train_rul),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(100, 6), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(100, 1), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "    )\n",
    ").batch(batch_size).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(val_current_seq, val_vibration_seq, val_rul),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(100, 6), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(100, 1), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "    )\n",
    ").batch(batch_size).repeat()\n",
    "\n",
    "# Check dataset shapes and types\n",
    "for data, label in train_dataset.take(1):\n",
    "    print(\"Batch data shapes:\", [d.shape for d in data], \"Batch label shape:\", label.shape)\n",
    "    print(\"Batch data types:\", [d.dtype for d in data], \"Batch label dtype:\", label.dtype)\n",
    "\n",
    "for data, label in val_dataset.take(1):\n",
    "    print(\"Batch data shapes:\", [d.shape for d in data], \"Batch label shape:\", label.shape)\n",
    "    print(\"Batch data types:\", [d.dtype for d in data], \"Batch label dtype:\", label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom layers for time and channel attention\n",
    "class TimeAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, **kwargs):\n",
    "        super(TimeAttentionLayer, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_h = tf.keras.layers.Dense(hidden_size)\n",
    "        self.W_t = tf.keras.layers.Dense(hidden_size)\n",
    "        self.v = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h_t = inputs\n",
    "        u_t = tf.nn.tanh(self.W_h(h_t) + tf.expand_dims(self.W_t(h_t[:, -1, :]), axis=1))\n",
    "        a_t = tf.nn.softmax(self.v(u_t), axis=1)\n",
    "        S_t = tf.reduce_sum(a_t * h_t, axis=1)\n",
    "        return S_t\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(TimeAttentionLayer, self).get_config()\n",
    "        config.update({\"hidden_size\": self.hidden_size})\n",
    "        return config\n",
    "\n",
    "class ChannelAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super(ChannelAttentionLayer, self).__init__(**kwargs)\n",
    "        self.num_channels = num_channels\n",
    "        self.W_v = tf.keras.layers.Dense(num_channels)\n",
    "        self.W_m = tf.keras.layers.Dense(num_channels)\n",
    "        self.W_n = tf.keras.layers.Dense(num_channels)\n",
    "        # Adjust the output dimension of W_a to 1 for a single attention weight\n",
    "        self.W_a = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        H = inputs\n",
    "        v_j = GlobalAvgPool1D()(H)\n",
    "        m_j = GlobalMaxPooling1D()(H)\n",
    "        n_j = tf.reduce_sum(H, axis=1)\n",
    "        concatenated = tf.concat([v_j, m_j, n_j], axis=1)\n",
    "        r = tf.nn.relu(self.W_v(concatenated) + self.W_m(concatenated) + self.W_n(concatenated))\n",
    "        # Calculate a single attention weight for the entire time series\n",
    "        attention_weight = self.W_a(r)\n",
    "        # Apply attention weight to the input H\n",
    "        attention_output = attention_weight * H\n",
    "        return attention_output # Output maintains the shape of H\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ChannelAttentionLayer, self).get_config()\n",
    "        config.update({\"num_channels\": self.num_channels})\n",
    "        return config\n",
    "\n",
    "# Define a custom layer for expand_dims\n",
    "class ExpandDimsLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(ExpandDimsLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ExpandDimsLayer, self).get_config()\n",
    "        config.update({\"axis\": self.axis})\n",
    "        return config\n",
    "\n",
    "class SqueezeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(SqueezeLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Handle the batch dimension\n",
    "        if inputs.shape[self.axis] == 1:\n",
    "            return tf.squeeze(inputs, axis=self.axis)\n",
    "        else:\n",
    "            return inputs  # Return the input as is if the dimension is not 1\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(SqueezeLayer, self).get_config()\n",
    "        config.update({\"axis\": self.axis})\n",
    "        return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Handle the case where the axis is squeezed\n",
    "        if input_shape[self.axis] == 1:\n",
    "            output_shape = list(input_shape)\n",
    "            del output_shape[self.axis]\n",
    "            return tuple(output_shape)\n",
    "        else:\n",
    "            return input_shape  # Return the original shape if not squeezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape for stator and rotor data\n",
    "stator_input_shape = (100, 6) # (sequence_length, number of stator features)\n",
    "rotor_input_shape = (100, 1) # (sequence_length, number of rotor features)\n",
    "\n",
    "# Define the model with modified channel attention mechanism and dropout\n",
    "def build_model(hp):\n",
    "    hidden_size = hp.Int('hidden_size', min_value=32, max_value=128, step=32)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.6, step=0.2)\n",
    "    dense_size = hp.Int('dense_size', min_value=32, max_value=128, step=32)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-1, sampling='log')\n",
    "\n",
    "    # Stator current input\n",
    "    input_stator = Input(shape=stator_input_shape, name='stator_input')\n",
    "    lstm_stator = Bidirectional(LSTM(hidden_size, return_sequences=True))(input_stator)\n",
    "    time_attention_stator = TimeAttentionLayer(hidden_size)(lstm_stator)\n",
    "\n",
    "    # Rotor vibration input\n",
    "    input_rotor = Input(shape=rotor_input_shape, name='rotor_input')\n",
    "    lstm_rotor = Bidirectional(LSTM(hidden_size, return_sequences=True))(input_rotor)\n",
    "    time_attention_rotor = TimeAttentionLayer(hidden_size)(lstm_rotor)\n",
    "\n",
    "    # Concatenate and Dense layers with Dropout\n",
    "    concatenated = Concatenate()([time_attention_stator, time_attention_rotor])\n",
    "    expanded = ExpandDimsLayer(axis=1)(concatenated)\n",
    "    channel_attention_layer = ChannelAttentionLayer(hidden_size * 2)(expanded)\n",
    "    squeezed = SqueezeLayer(axis=1)(channel_attention_layer)\n",
    "    dense1 = Dense(dense_size, activation='relu')(squeezed)\n",
    "    dropout1 = Dropout(dropout_rate)(dense1)\n",
    "    output = Dense(1)(dropout1)\n",
    "\n",
    "    model = Model(inputs=[input_stator, input_rotor], outputs=output)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Print model summary for debugging\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Add this ProfilingCallback to your callbacks list\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=5)\n",
    "\n",
    "callbacks = [early_stopping, tensorboard_callback]\n",
    "\n",
    "# Setup the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='mca_bilstm_tuning'\n",
    ")\n",
    "\n",
    "# Manually set steps_per_epoch and validation_steps\n",
    "steps_per_epoch = len(train_current_seq) // batch_size\n",
    "validation_steps = len(val_current_seq) // batch_size\n",
    "\n",
    "# Display the search space summary\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(train_dataset, steps_per_epoch=steps_per_epoch, epochs=5,\n",
    "             validation_data=val_dataset, validation_steps=validation_steps,\n",
    "             callbacks=callbacks)\n",
    "\n",
    "\n",
    "# function to check if the graphviz package is working properly\n",
    "def check_graphviz():\n",
    "    try:\n",
    "        # Attempt to create an image of a blank graph to check the pydot/graphviz installation.\n",
    "        pydot.Dot.create(pydot.Dot())\n",
    "        return True\n",
    "    except (OSError, Exception) as e:\n",
    "        if isinstance(e, OSError):\n",
    "            print(\"Graphviz not found.\")\n",
    "        else:\n",
    "            print(\"Some other exception occurred with pydot.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training and validation data generators\n",
    "print(\"Checking train generator...\")\n",
    "for batch in train_generator_minmax:\n",
    "    x_batch, y_batch = batch\n",
    "    print(\"X stator shape:\", x_batch[0].shape)\n",
    "    print(\"X rotor shape:\", x_batch[1].shape)\n",
    "    print(\"Y shape:\", y_batch.shape)\n",
    "    print(\"First batch Y values:\", y_batch[:5])\n",
    "    break\n",
    "\n",
    "print(\"Checking validation generator...\")\n",
    "for batch in validation_generator_minmax:\n",
    "    x_batch, y_batch = batch\n",
    "    print(\"X stator shape:\", x_batch[0].shape)\n",
    "    print(\"X rotor shape:\", x_batch[1].shape)\n",
    "    print(\"Y shape:\", y_batch.shape)\n",
    "    print(\"First batch Y values:\", y_batch[:5])\n",
    "    break\n",
    "\n",
    "# Ensure there are no NaN values in the data\n",
    "print(\"Checking for NaN values in training data...\")\n",
    "print(\"NaNs in current sequences:\", np.isnan(current_sequences_minmax).sum())\n",
    "print(\"NaNs in vibration sequences:\", np.isnan(vibration_sequences_minmax).sum())\n",
    "print(\"NaNs in RUL:\", np.isnan(rul_minmax).sum())\n",
    "\n",
    "print(\"Checking for NaN values in validation data...\")\n",
    "print(\"NaNs in current sequences:\", np.isnan(val_current_seq_minmax).sum())\n",
    "print(\"NaNs in vibration sequences:\", np.isnan(val_vibration_seq_minmax).sum())\n",
    "print(\"NaNs in RUL:\", np.isnan(val_rul_minmax).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 64\n",
    "dropout_rate = 0.3\n",
    "dense_size = 128\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_mca_bilstm_model(hidden_size, dropout_rate, dense_size)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model with debugging\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch+1}/5\")\n",
    "    for step, batch in enumerate(train_generator_minmax):\n",
    "        x_batch, y_batch = batch\n",
    "        print(f\"Step {step+1}: X stator shape: {x_batch[0].shape}, X rotor shape: {x_batch[1].shape}, Y shape: {y_batch.shape}\")\n",
    "        if step >= 10:  # Limit to 10 steps for debugging\n",
    "            break\n",
    "    model.fit(train_generator, epochs=1, validation_data=validation_generator)\n",
    "    print(\"Training step completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_thesis_309",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
