{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Concatenate, Multiply, Permute, Lambda, GlobalMaxPooling1D, GlobalAvgPool1D, Reshape, Activation, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import pydot, graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all of the CSV file paths\n",
    "stator_csv_files = [r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\01_SCIM_current_allfault_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\02_SCIM_current_PTPab_400V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\03_SCIM_current_PTPab_480V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\04_SCIM_current_PTGa_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\05_SCIM_current_PTGb_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\06_SCIM_current_PTGc_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\07_SCIM_current_PTPbc_400V.csv\"]\n",
    "\n",
    "rotor_csv_files = [r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\01_SCIM_vibration_allfault_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\02_SCIM_vibration_PTPab_400V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\03_SCIM_vibration_PTPab_480V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\04_SCIM_vibration_PTGa_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\05_SCIM_vibration_PTGb_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\06_SCIM_vibration_PTGc_360V.csv\",\n",
    "r\"D:\\MTdataset\\DL_dataset\\Simulink_data_generation\\Final_current_vibration_data\\07_SCIM_vibration_PTPbc_400V.csv\"]\n",
    "\n",
    "# Read the CSV files into pandas dataframe and convert to numpy arrays\n",
    "stator_data = [pd.read_csv(file).values for file in stator_csv_files]\n",
    "rotor_data = [pd.read_csv(file).values for file in rotor_csv_files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(stator_data, rotor_data, sequence_length=100, batch_size=32):\n",
    "    # get the number of samples\n",
    "    num_samples = stator_data[0].shape[0] - sequence_length     \n",
    "\n",
    "    # Infinite loop to continuously yield the batches\n",
    "    while True:\n",
    "        # Generate batches\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            stator_batch = []\n",
    "            rotor_batch = []\n",
    "            batch_y = []\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                end_idx = start_idx + i + sequence_length\n",
    "                if end_idx >= num_samples:\n",
    "                    break\n",
    "\n",
    "            # Create sequences of length 'Sequence length'\n",
    "            stator_seq = [data[start_idx + i:end_idx, 1:] for data in stator_data] # excluding the time column\n",
    "            rotor_seq = [data[start_idx + i:end_idx, 1] for data in rotor_data] # excluding the time column & vibration is the only remaining column\n",
    "            \n",
    "            # Target is the next time step's 'Time' value in stator data (same as rotor data)\n",
    "            y = stator_data[0][end_idx, 0] # assuming time is the first column in the stator files\n",
    "\n",
    "            stator_batch.append(np.concatenate(stator_seq, axis=-1))\n",
    "            rotor_batch.append(np.concatenate(rotor_seq, axis=-1))\n",
    "            batch_y.append(y)\n",
    "        \n",
    "        if len(stator_batch) == batch_size:\n",
    "            X_stator = np.array(stator_batch)\n",
    "            X_rotor = np.array(rotor_batch)\n",
    "            y = np.array(batch_y)\n",
    "\n",
    "            #concatenating data along the last axis\n",
    "            yield [X_stator, X_rotor], y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data generator\n",
    "\n",
    "generator = data_generator(stator_data, rotor_data, sequence_length=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the BiLSTM network with Time and Channel attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time attention mechanism \n",
    "class TimeAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TimeAttentionLayer, self).__init__(**kwargs)\n",
    "        self.W_omega = None\n",
    "        self.b_omega = None\n",
    "        self.u_omega = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        hidden_size = int(input_shape[-1])\n",
    "        self.W_omega = self.add_weight(name='W_omega', shape=(hidden_size, hidden_size), initializer='uniform', trainable=True)\n",
    "        self.b_omega = self.add_weight(name='b_omega', shape=(hidden_size,), initializer='uniform', trainable=True)\n",
    "        self.u_omega = self.add_weight(name='u_omega', shape=(hidden_size,), initializer='uniform', trainable=True)\n",
    "        super(TimeAttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        u_t = tf.nn.tanh(tf.tensordot(inputs, self.W_omega, axes=1) + self.b_omega)\n",
    "        alpha_t = tf.nn.softmax(tf.reduce_sum(u_t * self.u_omega, axis=2, keepdims=True), axis=1)\n",
    "        context_vector = tf.reduce_sum(alpha_t * inputs, axis=1)\n",
    "        return context_vector\n",
    "\n",
    "class ChannelAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ChannelAttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.dense1 = Dense(input_shape[-1] // 8, activation='relu')\n",
    "        self.dense2 = Dense(input_shape[-1], activation='linear')\n",
    "        self.dense3 = Dense(input_shape[-1], activation='linear')\n",
    "        self.activation = Activation('hard_sigmoid')\n",
    "        super(ChannelAttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # GMP and GAP for descriptors m and v\n",
    "        gmp = GlobalMaxPooling1D()(inputs)\n",
    "        gap = GlobalAvgPool1D()(inputs)\n",
    "        \n",
    "        # Fully Connected Layer for descriptor n\n",
    "        fcl = self.dense3(inputs)\n",
    "        \n",
    "        # Descriptors\n",
    "        m = self.dense1(gmp)\n",
    "        v = self.dense1(gap)\n",
    "        n = self.dense1(fcl)\n",
    "        \n",
    "        # Multilayer Perceptrons\n",
    "        W12 = self.dense2(v)\n",
    "        W22 = self.dense2(m)\n",
    "        \n",
    "        # Combine using element-wise summation and add n\n",
    "        combined = Add()([W12, W22, n])\n",
    "        \n",
    "        # Activation function to get attention weights\n",
    "        attention_weights = self.activation(combined)\n",
    "        attention_weights = Reshape((1, self.input_shape[-1]))(attention_weights)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        channel_attention = Multiply()([inputs, attention_weights])\n",
    "        \n",
    "        return channel_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m stator_input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m6\u001b[39m) \u001b[38;5;66;03m# (sequence_length, number of stator features)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m rotor_input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (sequence_length, number of rotor features)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstator_input_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotor_input_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msummary\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fit the model using the data generator\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# model.fit(generator, steps_per_epoch=(stator_data[0].shape[0] - 100) // 32, epochs=10)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(stator_input_shape, rotor_input_shape)\u001b[0m\n\u001b[0;32m      5\u001b[0m lstm_stator \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(input_stator)\n\u001b[0;32m      6\u001b[0m time_attention_stator \u001b[38;5;241m=\u001b[39m TimeAttentionLayer()(lstm_stator)\n\u001b[1;32m----> 7\u001b[0m channel_attention_stator \u001b[38;5;241m=\u001b[39m ChannelAttentionLayer()(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_attention_stator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Rotor vibration input\u001b[39;00m\n\u001b[0;32m     10\u001b[0m input_rotor \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39mrotor_input_shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrotor_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\daryl\\anaconda3\\envs\\DL_thesis\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\daryl\\anaconda3\\envs\\DL_thesis\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\daryl\\anaconda3\\envs\\DL_thesis\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# Define the model with modified channel attention mechanism and dropout\n",
    "def create_model(stator_input_shape, rotor_input_shape):\n",
    "    # Stator current input\n",
    "    input_stator = Input(shape=stator_input_shape, name='stator_input')\n",
    "    lstm_stator = Bidirectional(LSTM(64, return_sequences=True))(input_stator)\n",
    "    time_attention_stator = TimeAttentionLayer()(lstm_stator)\n",
    "    channel_attention_stator = ChannelAttentionLayer()(tf.expand_dims(time_attention_stator, 1))\n",
    "\n",
    "    # Rotor vibration input\n",
    "    input_rotor = Input(shape=rotor_input_shape, name='rotor_input')\n",
    "    lstm_rotor = Bidirectional(LSTM(64, return_sequences=True))(input_rotor)\n",
    "    time_attention_rotor = TimeAttentionLayer()(lstm_rotor)\n",
    "    channel_attention_rotor = ChannelAttentionLayer()(tf.expand_dims(time_attention_rotor, 1))\n",
    "\n",
    "    # Concatenate and Dense layers with Dropout\n",
    "    concatenated = Concatenate()([channel_attention_stator, channel_attention_rotor])\n",
    "    dense1 = Dense(64, activation='relu')(concatenated)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    output = Dense(1)(dropout1)\n",
    "\n",
    "    model = Model(inputs=[input_stator, input_rotor], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# input shape for stator and rotor data\n",
    "stator_input_shape = (100, 6) # (sequence_length, number of stator features)\n",
    "rotor_input_shape = (100, 1) # (sequence_length, number of rotor features)\n",
    "\n",
    "model = create_model(stator_input_shape, rotor_input_shape)\n",
    "model.summary\n",
    "\n",
    "# Fit the model using the data generator\n",
    "# model.fit(generator, steps_per_epoch=(stator_data[0].shape[0] - 100) // 32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling ChannelAttentionLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'channel_attention_layer_3' (of type ChannelAttentionLayer). Either the `ChannelAttentionLayer.call()` method is incorrect, or you need to implement the `ChannelAttentionLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nInputs have incompatible shapes. Received shapes (100, 16) and (128,)\u001b[0m\n\nArguments received by ChannelAttentionLayer.call():\n  • args=('<KerasTensor shape=(None, 100, 128), dtype=float32, sparse=None, name=keras_tensor_45>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m time_attention_model \u001b[38;5;241m=\u001b[39m visualize_time_attention((\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m128\u001b[39m))  \u001b[38;5;66;03m# Adjust input_shape accordingly\u001b[39;00m\n\u001b[0;32m     25\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(time_attention_model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attention_model.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m channel_attention_model \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_channel_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust input_shape accordingly\u001b[39;00m\n\u001b[0;32m     28\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(channel_attention_model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_attention_model.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Visualize the entire model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m, in \u001b[0;36mvisualize_channel_attention\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_channel_attention\u001b[39m(input_shape):\n\u001b[0;32m     15\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m---> 16\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[43mChannelAttentionLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minput_layer, outputs\u001b[38;5;241m=\u001b[39mattention_output)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\daryl\\anaconda3\\envs\\DL_thesis\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[36], line 52\u001b[0m, in \u001b[0;36mChannelAttentionLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     49\u001b[0m W22 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Combine using element-wise summation and add n\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mW12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW22\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Activation function to get attention weights\u001b[39;00m\n\u001b[0;32m     55\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(combined)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception encountered when calling ChannelAttentionLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'channel_attention_layer_3' (of type ChannelAttentionLayer). Either the `ChannelAttentionLayer.call()` method is incorrect, or you need to implement the `ChannelAttentionLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nInputs have incompatible shapes. Received shapes (100, 16) and (128,)\u001b[0m\n\nArguments received by ChannelAttentionLayer.call():\n  • args=('<KerasTensor shape=(None, 100, 128), dtype=float32, sparse=None, name=keras_tensor_45>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# Visualization Functions\n",
    "def visualize_bilstm(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    bilstm_layer = Bidirectional(LSTM(64, return_sequences=True))(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=bilstm_layer)\n",
    "    return model\n",
    "\n",
    "def visualize_time_attention(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    attention_output = TimeAttentionLayer()(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=attention_output)\n",
    "    return model\n",
    "\n",
    "def visualize_channel_attention(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    attention_output = ChannelAttentionLayer()(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=attention_output)\n",
    "    return model\n",
    "\n",
    "\n",
    "bilstm_model = visualize_bilstm((100, 6))  # Adjust input_shape accordingly\n",
    "tf.keras.utils.plot_model(bilstm_model, to_file='bilstm_model.png', show_shapes=True)\n",
    "\n",
    "time_attention_model = visualize_time_attention((100, 128))  # Adjust input_shape accordingly\n",
    "tf.keras.utils.plot_model(time_attention_model, to_file='time_attention_model.png', show_shapes=True)\n",
    "\n",
    "channel_attention_model = visualize_channel_attention((100, 128))  # Adjust input_shape accordingly\n",
    "tf.keras.utils.plot_model(channel_attention_model, to_file='channel_attention_model.png', show_shapes=True)\n",
    "\n",
    "# Visualize the entire model\n",
    "tf.keras.utils.plot_model(model, to_file='full_model.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_thesis-python",
   "language": "python",
   "name": "dl_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
